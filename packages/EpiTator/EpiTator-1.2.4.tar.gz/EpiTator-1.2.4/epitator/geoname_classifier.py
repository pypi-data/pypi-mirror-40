"""
This script was generated by the train.py script in this repository:
https://github.com/ecohealthalliance/geoname-annotator-training
"""
import numpy as np
from numpy import array, int32


HIGH_CONFIDENCE_THRESHOLD = 0.5
GEONAME_SCORE_THRESHOLD = 0.1
base_classifier =\
{
    'C': 0.05,
    'tol': 0.0001,
    'max_iter': 100,
    'multi_class': 'warn',
    'solver': 'liblinear',
    'class_weight': None,
    'intercept_': array([-12.96847368]),
    'fit_intercept': True,
    'dual': False,
    'n_iter_': array([34], dtype=int32),
    'n_jobs': None,
    'classes_': array([False,  True]),
    'random_state': None,
    'warm_start': False,
    'verbose': 0,
    'penalty': 'l1',
    'intercept_scaling': 1,
    'coef_': array([[
        # log_population
        0.3400265114642491,
        # name_count
        0.18126370788639004,
        # names_used
        1.0416505478329494,
        # exact_name_match
        0.48689572888105914,
        # multiple_spans
        0.22213375908341862,
        # span_length
        0.16577113689171946,
        # cannonical_name_used
        2.6193075762116154,
        # loc_NE_portion
        0.8983857499144656,
        # other_NE_portion
        -0.5361526642339721,
        # noun_portion
        0.0,
        # num_tokens
        0.44255248015322196,
        # med_token_prob
        -0.33997541370846585,
        # exact_alternatives
        -0.8703166373667724,
        # PPL_feature_code
        -0.8950069636944499,
        # ADM_feature_code
        -1.0800760155305875,
        # PCL_feature_code
        2.305217045860327,
        # other_feature_code
        0.0,
        # first_order
        0.8649855654975414,
        # combined_span
        1.5066603200498148,
        # close_locations
        0.0,
        # very_close_locations
        0.0,
        # base_score
        0.0,
        # base_score_margin
        0.0,
        # contained_locations
        0.0,
        # containing_locations
        0.0,
    ]]),
}

contextual_classifier =\
{
    'C': 0.05,
    'tol': 0.0001,
    'max_iter': 100,
    'multi_class': 'warn',
    'solver': 'liblinear',
    'class_weight': None,
    'intercept_': array([-11.07012273]),
    'fit_intercept': True,
    'dual': False,
    'n_iter_': array([36], dtype=int32),
    'n_jobs': None,
    'classes_': array([False,  True]),
    'random_state': None,
    'warm_start': False,
    'verbose': 0,
    'penalty': 'l1',
    'intercept_scaling': 1,
    'coef_': array([[
        # log_population
        0.26919239530569744,
        # name_count
        0.15391926141591555,
        # names_used
        0.6093336386171238,
        # exact_name_match
        0.0,
        # multiple_spans
        0.04710799001512861,
        # span_length
        0.15858394656503427,
        # cannonical_name_used
        2.0938712567600373,
        # loc_NE_portion
        1.1419115133690598,
        # other_NE_portion
        -0.23217155527316988,
        # noun_portion
        0.0,
        # num_tokens
        0.41401940754982003,
        # med_token_prob
        -0.23775837288538074,
        # exact_alternatives
        -0.6874573373702897,
        # PPL_feature_code
        -0.47120680323948294,
        # ADM_feature_code
        -0.6101137869203587,
        # PCL_feature_code
        1.722979737294853,
        # other_feature_code
        0.0,
        # first_order
        0.6738287702092822,
        # combined_span
        0.0,
        # close_locations
        0.16276667569596484,
        # very_close_locations
        0.007244809408803627,
        # base_score
        -0.015164066836945362,
        # base_score_margin
        2.4171623267857085,
        # contained_locations
        0.059708073294993246,
        # containing_locations
        0.673294874427792,
    ]]),
}

# Logistic regression code from scipy
def predict_proba(X, classifier):
    """Probability estimation for OvR logistic regression.
    Positive class probabilities are computed as
    1. / (1. + np.exp(-classifier.decision_function(X)));
    multiclass is handled by normalizing that over all classes.
    """
    prob = np.dot(X, classifier['coef_'].T) + classifier['intercept_']
    prob = prob.ravel() if prob.shape[1] == 1 else prob
    prob *= -1
    np.exp(prob, prob)
    prob += 1
    np.reciprocal(prob, prob)
    if prob.ndim == 1:
        return np.vstack([1 - prob, prob]).T
    else:
        # OvR normalization, like LibLinear's predict_probability
        prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))
        return prob


def predict_proba_base(X):
    return predict_proba(X, base_classifier)


def predict_proba_contextual(X):
    return predict_proba(X, contextual_classifier)
