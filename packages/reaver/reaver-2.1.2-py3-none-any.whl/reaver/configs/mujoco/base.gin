# params for generic actor-critic:
# ==========================================
build_mlp.activation = 'relu'
build_mlp.value_separate = True
build_mlp.obs_shift = True
build_mlp.obs_scale = True

ACAgent.model_fn = @build_mlp
ACAgent.policy_cls = @MultiPolicy

ACAgent.optimizer = @tf.train.AdamOptimizer()
tf.train.AdamOptimizer.learning_rate = 0.0003

ACAgent.value_coef = 0.5
ACAgent.entropy_coef = 0.0

ACAgent.batch_sz = 4
ACAgent.traj_len = 512

ACAgent.discount = 0.99
ACAgent.gae_lambda = 0.0

ACAgent.clip_rewards = 0.0
ACAgent.clip_grads_norm = 0.0

ACAgent.normalize_advantages = False

# params for A2C:
# ==========================================
# ...

# params for PPO:
# ==========================================
PPOAgent.n_epochs = 10
PPOAgent.minibatch_sz = 64
PPOAgent.clip_ratio = 0.2
PPOAgent.clip_value = 0.0

PPOAgent.gae_lambda = 0.95