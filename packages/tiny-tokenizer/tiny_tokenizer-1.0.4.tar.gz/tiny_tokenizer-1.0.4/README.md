# Tiny Tokenizer: Basic sentence/word Tokenizer

### Requirements

- Python
- MeCab
- KyTea

### Quick start

`make`

### Custom Operation

#### Get Wikipedia Dump

`make get-wikipedia`

#### Preprocessing

`make tokenize`

#### Run test

`make test`
