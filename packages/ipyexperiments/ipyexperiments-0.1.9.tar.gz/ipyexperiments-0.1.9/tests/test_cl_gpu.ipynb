{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellLogger subsystem\n",
    "\n",
    "This test tests the CellLogger subsystem, accessible via `exp.cl` once one of the `IPyExperiments` subclasses has been initiated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test specifics\n",
    "\n",
    "Since we need to validate the the output, we have to capture it first. The way jupyter is setup, is that in once cell you set up a capture with `%%capture` magick and then in the next cell you can analyze it. That's why each test group has two cells, the first one doing the action to be tested and the following one doing the validatations.\n",
    "\n",
    "Moreover, the output of this test becomes confusing because the capture mechanism somehow messes things up which leads to re-running the `post_run_cell` callback of the CellLogger subsystem again - as a result you get a bogus output with 0's regardless of the code being run. It doesn't interfere with the testing, but it does interfere with things like `.data` which gets reset because of that, showing invalid information - therefore we can only test `.data` w/o capturing the cell's output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyexperiments import *\n",
    "from utils.text import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipyexperiments.cell_logger.CellLogger at 0x7f1bb5ef9c88>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.001s\n",
      "･ CPU:         0       0     2154 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "#if 'exp' in locals(): exp.cl.stop() # helps debug\n",
    "exp1 = IPyExperimentsPytorch(exp_enable=False)\n",
    "exp1.cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.129s\n",
      "･ CPU:         0       0     2282 MB   |\n",
      "･ GPU:         0       0     2494 MB   |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "gpu1 = consume_gpu_ram_256mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.117s\n",
      "| ･ CPU:       128       0     2282 MB   |\n",
      "| ･ GPU:       256       0     2494 MB   |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.006s\n",
      "･ CPU:         0       0     2154 MB   |\n",
      "･ GPU:      -256     256     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_strings(output)\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=0, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=0, abs_tol=0)\n",
    "\n",
    "# cleanup\n",
    "del cpu1, gpu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume/release leading to positive peak numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.246s\n",
      "･ CPU:         0       0     2283 MB   |\n",
      "･ GPU:         0     256     2494 MB   |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test peak measurement\n",
    "# here we consume 256MB of RAM and release 128MB \n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_peak_memory_usage'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.235s\n",
      "| ･ CPU:       128     128     2283 MB   |\n",
      "| ･ GPU:       256     256     2494 MB   |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.006s\n",
      "･ CPU:         0       0     2155 MB   |\n",
      "･ GPU:      -256       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_peak_memory_usage\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=128, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=256, abs_tol=2)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .data accessor validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.272s\n",
      "･ CPU:       128     128     2283 MB   |\n",
      "･ GPU:       256     256     2494 MB   |\n"
     ]
    }
   ],
   "source": [
    "# no capture! breaks .data since it re-runs the post_run_cell, again, resetting .data\n",
    "# here we consume 256MB of RAM and release 128MB - so that we can test peak measurement\n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB - so that we can test peak measurement\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "## Consume/Release Positive Peak\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_data_accessor'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134224166\n",
      "134231924\n",
      "268435456\n",
      "268435456\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.006s\n",
      "･ CPU:         0       0     2155 MB   |\n",
      "･ GPU:      -256     256     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_data_accessor\"\"\"\n",
    "cpu_mem, gpu_mem, time_data = exp1.cl.data\n",
    "\n",
    "check_match(consumed_reported=b2mb(cpu_mem.used_delta), peaked_reported=b2mb(cpu_mem.peaked_delta), \n",
    "            consumed_expected=128,                      peaked_expected=128,  abs_tol=1)\n",
    "check_match(consumed_reported=b2mb(gpu_mem.used_delta), peaked_reported=b2mb(gpu_mem.peaked_delta), \n",
    "            consumed_expected=256,                      peaked_expected=256, abs_tol=1)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_stop'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.040s\n",
      "･ CPU:         0       0     2155 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_stop\"\"\"\n",
    "exp1.cl.stop()\n",
    "#check that no output appears after this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No captured output\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "assert output == \"\", \"there should be no output as logger has been stopped\"\n",
    "\n",
    "# cleanup\n",
    "del cpu1\n",
    "del exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'exp10' in locals(): del exp10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.033s\n",
      "･ CPU:         0       0     2155 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# this one tests with the exp-system turned on, cl-system turned on\n",
    "# this is a pretty normal situation, considering that someone will be reloading the same cell\n",
    "# do not change this test!\n",
    "exp10 = IPyExperimentsPytorch(exp_enable=True, cl_enable=True)\n",
    "exp10 = IPyExperimentsPytorch(exp_enable=True, cl_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:  Used  Free  Total      Util\n",
      "| CPU:  2155  8219  31588 MB   6.82% \n",
      "| GPU:  2238  5881   8119 MB  27.56% \n",
      "| \n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:  Used  Free  Total      Util\n",
      "| CPU:  2155  8219  31588 MB   6.82% \n",
      "| GPU:  2238  5881   8119 MB  27.56% \n",
      "| \n",
      "| \n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.024s\n",
      "| ･ CPU:         0       0     2155 MB   |\n",
      "| ･ GPU:         0       0     2238 MB   |\n",
      "| IPyExperimentsPytorch: Finishing\n",
      "| \n",
      "| *** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "| \n",
      "| *** Experiment memory:\n",
      "| RAM:  Consumed     Reclaimed\n",
      "| CPU:       0       0 MB (100.00%)\n",
      "| GPU:       0       0 MB (100.00%)\n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:  Used  Free  Total      Util\n",
      "| CPU:  2155  8219  31588 MB   6.82% \n",
      "| GPU:  2238  5881   8119 MB  27.56% \n",
      "| \n",
      "| \n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.021s\n",
      "| ･ CPU:         0       0     2155 MB   |\n",
      "| ･ GPU:         0       0     2238 MB   |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.455s\n",
      "･ CPU:         0       0     2155 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\"\n",
    "\n",
    "match = re.findall(r'started', output)\n",
    "assert len(match) == 2, f\"should have started twice, got {len(match)}\"\n",
    "\n",
    "match = re.findall(r'Finishing', output)\n",
    "assert len(match) == 1, f\"should have finished once, got {len(match)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.327s\n",
      "･ CPU:         0       0     2155 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n",
      "IPyExperimentsPytorch: Finishing\n",
      "\n",
      "*** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "\n",
      "*** Newly defined local variables:\n",
      "Deleted: match\n",
      "\n",
      "*** Experiment memory:\n",
      "RAM:  Consumed     Reclaimed\n",
      "CPU:       0       0 MB (  0.00%)\n",
      "GPU:       0       0 MB (100.00%)\n",
      "\n",
      "*** Current state:\n",
      "RAM:  Used  Free  Total      Util\n",
      "CPU:  2155  8219  31588 MB   6.82% \n",
      "GPU:  2238  5881   8119 MB  27.56% \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cleanup\n",
    "del exp10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.023s\n",
      "･ CPU:         0       0     2155 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# this one tests with the exp-system turned off, cl-system turned on\n",
    "# this is a pretty normal situation, considering that someone will be reloading the same cell\n",
    "# do not change this test!\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False, cl_enable=True)\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False, cl_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX 1070 Ti (8119 RAM)\n",
      "| \n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.022s\n",
      "| ･ CPU:         0       0     2155 MB   |\n",
      "| ･ GPU:         0       0     2238 MB   |\n",
      "| ･ RAM: △Consumed △Peaked  Used Total | Exec time 0.011s\n",
      "| ･ CPU:         0       0     2155 MB   |\n",
      "| ･ GPU:         0       0     2238 MB   |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.001s\n",
      "･ CPU:         0       0     2155 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM: △Consumed △Peaked  Used Total | Exec time 0.039s\n",
      "･ CPU:         0       0     2155 MB   |\n",
      "･ GPU:         0       0     2238 MB   |\n"
     ]
    }
   ],
   "source": [
    "# cleanup\n",
    "del exp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript # prevent committing an unsaved notebook\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "323px",
    "left": "956px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
